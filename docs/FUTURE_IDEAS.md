## Future ideas and long-range wishes (non-binding)

Purpose: capture ideas that are not yet committed to the core plan. Revisit after the
core stages are stable and tested.

### Retina and attention control
- Adaptive Gaussian sigma based on uncertainty or novelty.
- Multi-fovea sampling and peripheral motion triggers.
- Attractor networks to stabilize attention state over time.

### Representation and learning
- Autoencoders for dimensionality reduction once embeddings stabilize.
- Heteroassociative networks to link percepts to tokens or labels.
- Predictive coding with deeper top-down feedback loops.
- Dynamic DAG that cascades from low-level parts to categories.

### Memory, language, and declarative knowledge
- Object tokenization as "object files" linked to stable track UUIDs.
- External declarative memory store (knowshowgo or equivalent).
- Language tags attached to tokens and prototypes with associative recall.
- Reward-modulated association for teaching labels and actions.

### Temporal and bio-inspired extensions
- Recurrent networks (GRU/LSTM) for temporal binding.
- Spiking neural networks and spike-timing-dependent plasticity.
- Motion encoded as spike trains derived from tracking velocities.
- Habituation/sensitization dynamics with recovery and gain control.

### Evaluation and research directions
- Curriculum learning protocols that mirror human development.
- Ablation studies for novelty gating, predictive coding, and decay.
- Long-horizon stability benchmarks (no collapse, bounded memory growth).
